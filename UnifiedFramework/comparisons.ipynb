{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "027d0702",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import tracker\n",
    "import stats\n",
    "import visualizer\n",
    "import utils\n",
    "\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e50aa0a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85a6a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#videofile = \"Comparisons/10X Ph- 9Fps Wash Dil 1 16 P016an R1.mp4\"\n",
    "videofile = \"Comparisons/10X Ph- 9Fps Wash Dil 1 16 P017me R1.mp4\"\n",
    "#videofile = \"Comparisons/10X Ph- 9Fps Wash 1 16 P018cu R1.mp4\"\n",
    "\n",
    "# Visualize the input\n",
    "cap = cv2.VideoCapture(videofile)\n",
    "\n",
    "# Get the first frame\n",
    "ret, frame = cap.read()\n",
    "\n",
    "plt.imshow(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6e7237",
   "metadata": {},
   "source": [
    "### Feed through the tracking pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab48e8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(tracker)\n",
    "importlib.reload(utils)\n",
    "\n",
    "frames = utils.loadVideo(videofile,as_gray=True)\n",
    "f = tracker.determineCentroids(frames)\n",
    "t = tracker.trackCentroids(f)\n",
    "\n",
    "print(t.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5d4522",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(tracker)\n",
    "\n",
    "compute_segments = False\n",
    "if compute_segments:\n",
    "    final = tracker.segmentCells(frames, t)\n",
    "else:\n",
    "    final = t\n",
    "\n",
    "print(final.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb122236",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.saveDataFrame(final, videofile.split('.')[0] + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf7feda",
   "metadata": {},
   "source": [
    "### Use Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8e43fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(visualizer)\n",
    "\n",
    "visualizer.runVisualization(videofile, final, visualization=\"segments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55af0d3e",
   "metadata": {},
   "source": [
    "# Run Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef556948",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction = \"Comparisons/10X Ph- 9Fps Wash Dil 1 16 P016an R1_predicted.csv\"\n",
    "#groundtruth = \"Comparisons/10X Ph- 9Fps Wash Dil 1 16 P016an R1_corrected.csv\"\n",
    "#videofile = \"Comparisons/10X Ph- 9Fps Wash Dil 1 16 P016an R1.mp4\"\n",
    "\n",
    "prediction = \"Comparisons/10X Ph- 9Fps Wash Dil 1 16 P017me R1_predicted.csv\"\n",
    "groundtruth = \"Comparisons/10X Ph- 9Fps Wash Dil 1 16 P017me R1_corrected.csv\"\n",
    "videofile = \"Comparisons/10X Ph- 9Fps Wash Dil 1 16 P017me R1.mp4\"\n",
    "\n",
    "#prediction = \"Comparisons/10X Ph- 9Fps Wash 1 16 P018cu R1_predicted.csv\"\n",
    "#groundtruth = \"Comparisons/10X Ph- 9Fps Wash 1 16 P018cu R1_corrected.csv\"\n",
    "#videofile = \"Comparisons/10X Ph- 9Fps Wash 1 16 P018cu R1.mp4\"\n",
    "\n",
    "# Load as Pandas DataFrame\n",
    "pred_src = utils.loadDataFrame(prediction)\n",
    "gt_src = utils.loadDataFrame(groundtruth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3954f56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adhoc adjustment for testing\n",
    "#pred_src = gt_src"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b643b1",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90695cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6909 6904\n",
      "8157 8157\n",
      "6909\n",
      "6992\n",
      "51\n",
      "44\n",
      "43\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def dropDuplicates(df):\n",
    "      \n",
    "    # Detect duplicate rows based on 'col1' and 'col2'\n",
    "    #duplicate_rows = df[df.duplicated(subset=['frame', 'sperm'], keep='first')]\n",
    "    result = df.drop_duplicates(subset=['frame', 'sperm'], keep='first')\n",
    "\n",
    "    return result\n",
    "\n",
    "def interpolateTracks(df):\n",
    "\n",
    "    result = df.copy()\n",
    "\n",
    "    for sperm in range(0, df['sperm'].max() + 1):\n",
    "        sperm_frames = df[df['sperm'] == sperm]['frame'].values\n",
    "        if len(sperm_frames) > 1:\n",
    "            birth = np.amin(sperm_frames)\n",
    "            death = np.amax(sperm_frames)\n",
    "\n",
    "\n",
    "            # Find if the sperm exists for all frames\n",
    "            if len(sperm_frames) != death - birth + 1:\n",
    "                #print(\"Missing frames for sperm: \", sperm)\n",
    "                #print(\"Birth: \", birth, \", Death: \", death)\n",
    "                #print(\"Frames: \", sperm_frames)\n",
    "\n",
    "                for j in range(birth, death + 1):\n",
    "                    if j not in sperm_frames:\n",
    "                 \n",
    "                        # Find closest frame after the missing frame\n",
    "                        before = np.amax(sperm_frames[np.where(sperm_frames < j)])\n",
    "                        after = np.amin(sperm_frames[np.where(sperm_frames > j)])\n",
    "\n",
    "                        # interpolate x and y\n",
    "                        before_x = df[(df['sperm'] == sperm) & (df['frame'] == before)]['x'].values[0]\n",
    "                        before_y = df[(df['sperm'] == sperm) & (df['frame'] == before)]['y'].values[0]\n",
    "                        after_x = df[(df['sperm'] == sperm) & (df['frame'] == after)]['x'].values[0]\n",
    "                        after_y = df[(df['sperm'] == sperm) & (df['frame'] == after)]['y'].values[0]\n",
    "\n",
    "                        x = before_x + (after_x - before_x) * (j - before) / (after - before)\n",
    "                        y = before_y + (after_y - before_y) * (j - before) / (after - before)\n",
    "\n",
    "                        #print(\"Adding frame: \", j)\n",
    "                        #gt = gt.append({'frame': j, 'sperm': sperm, 'x': x, 'y': y}, ignore_index=True)\n",
    "                        result = pd.concat([result, pd.DataFrame([[j, sperm, x, y]], columns=['frame', 'sperm', 'x', 'y'])], ignore_index=True)\n",
    "\n",
    "    return result\n",
    "\n",
    "def filterSperm(df, epsilon=5.0):\n",
    "\n",
    "    filter_list = []\n",
    "\n",
    "    # Filter out sperm that are not moving\n",
    "    for sperm in df['sperm'].unique():\n",
    "        all_locs = df[df['sperm'] == sperm]\n",
    "        # Determine the mean sperm location\n",
    "        mean_loc = all_locs[['x', 'y']].mean()\n",
    "\n",
    "        # If the furthest away is less than e, remove the sperm\n",
    "        all_dists = all_locs[['x', 'y']].sub(mean_loc)\n",
    "        all_dists = all_dists.pow(2)\n",
    "        all_dists = all_dists.sum(axis=1)\n",
    "        all_dists = all_dists.pow(0.5)\n",
    "        if all_dists.max() < epsilon:\n",
    "            filter_list.append(sperm)\n",
    "\n",
    "    # Filter out sperm that are not moving\n",
    "    df = df[~df['sperm'].isin(filter_list)]\n",
    "\n",
    "    return df\n",
    "\n",
    "gt_u = dropDuplicates(gt_src)\n",
    "pred_u = dropDuplicates(pred_src)\n",
    "\n",
    "print(len(gt_src), len(gt_u))\n",
    "print(len(pred_src), len(pred_u))\n",
    "\n",
    "gt = interpolateTracks(gt_u)\n",
    "pred = interpolateTracks(pred_u)\n",
    "\n",
    "print(len(gt_src))\n",
    "print(len(gt))\n",
    "\n",
    "pred_filter = filterSperm(pred)\n",
    "gt_filter = filterSperm(gt)\n",
    "\n",
    "print(len(pred['sperm'].unique()))\n",
    "print(len(pred_filter['sperm'].unique()))\n",
    "\n",
    "print(len(gt['sperm'].unique()))\n",
    "print(len(gt_filter['sperm'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cc44dcd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118, 3)\n",
      "Video Finished.\n"
     ]
    }
   ],
   "source": [
    "# Visualize\n",
    "visualizer.runVisualization(videofile, pred_src, visualization=\"flow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b715743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118, 3)\n",
      "Video Finished.\n"
     ]
    }
   ],
   "source": [
    "visualizer.runVisualization(videofile, pred, visualization=\"flow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "07eb6a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 3)\n",
      "Video Finished.\n"
     ]
    }
   ],
   "source": [
    "visualizer.runVisualization(videofile, pred_filter, visualization=\"flow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845f4d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(94, 3)\n",
      "Video Finished.\n"
     ]
    }
   ],
   "source": [
    "visualizer.runVisualization(videofile, gt_src, visualization=\"flow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5479b2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(94, 3)\n",
      "Video Finished.\n"
     ]
    }
   ],
   "source": [
    "visualizer.runVisualization(videofile, gt, visualization=\"flow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "47ef76b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(109, 3)\n",
      "Video Finished.\n"
     ]
    }
   ],
   "source": [
    "visualizer.runVisualization(videofile, gt_filter, visualization=\"flow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c422aa",
   "metadata": {},
   "source": [
    "### Unlabeled Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da94437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def spermPerFrame(df, return_summary=False):\n",
    "    # Count occurrences of each sperm count in each frame\n",
    "    frame_counts = {}\n",
    "    max_sperm = df[\"sperm\"].max()\n",
    "    sperm_labels = list(range(max_sperm + 1))  # Generate labels from 0 to max_sperm\n",
    "\n",
    "    for frame in df[\"frame\"].unique():\n",
    "        frame_counts[frame] = df[df[\"frame\"] == frame][\"sperm\"].value_counts().reindex(sperm_labels).fillna(0)\n",
    "\n",
    "    # Create a DataFrame for sperm counts per frame\n",
    "    frame_summary = pd.DataFrame.from_dict(frame_counts, orient='index', columns=sperm_labels)\n",
    "    frame_summary.index.name = \"frame\"\n",
    "    frame_summary.reset_index(inplace=True)\n",
    "\n",
    "    # Add a column for total sperms observed in each frame\n",
    "    frame_summary[\"TotalSperms\"] = frame_summary[sperm_labels].sum(axis=1)\n",
    "\n",
    "    # Extract [\"TotalSperms\"] as numpy array\n",
    "    array = frame_summary[\"TotalSperms\"].values\n",
    "\n",
    "    if return_summary:\n",
    "        return array, frame_summary\n",
    "    else:\n",
    "        return array\n",
    "\n",
    "def framesPerSperm(df, return_summary=False):\n",
    "    sperm_counts = {}\n",
    "    max_frame = df[\"frame\"].max()\n",
    "    frame_labels = list(range(max_frame + 1)) # Generate labels from 0 to max_frame\n",
    "\n",
    "    for sperm in df[\"sperm\"].unique():\n",
    "        sperm_counts[sperm] = df[df[\"sperm\"] == sperm][\"frame\"].value_counts().reindex(frame_labels).fillna(0)\n",
    "\n",
    "    # Create a DataFrame for frame counts per sperm\n",
    "    sperm_summary = pd.DataFrame.from_dict(sperm_counts, orient='index', columns=frame_labels)\n",
    "    sperm_summary.index.name = \"sperm\"\n",
    "    sperm_summary.reset_index(inplace=True)\n",
    "\n",
    "    # Add a column for total sperms observed in each frame\n",
    "    sperm_summary[\"TotalFrames\"] = sperm_summary[frame_labels].sum(axis=1)\n",
    "\n",
    "    # Remove sperms that are not observed in any frame\n",
    "    sperm_summary = sperm_summary[sperm_summary[\"TotalFrames\"] > 0]\n",
    "\n",
    "    # Extract [\"TotalFrames\"] as numpy array\n",
    "    array = sperm_summary[\"TotalFrames\"].values\n",
    "\n",
    "    if return_summary:\n",
    "        return array, sperm_summary\n",
    "    else:\n",
    "        return array\n",
    "\n",
    "\n",
    "pred_spf = spermPerFrame(pred)\n",
    "gt_spf = spermPerFrame(gt)\n",
    "\n",
    "#print(pred_frames)\n",
    "#print(gt_frames)\n",
    "\n",
    "pred_fps = framesPerSperm(pred)\n",
    "gt_fps = framesPerSperm(gt)\n",
    "\n",
    "#print(pred_sperm)\n",
    "#print(gt_sperm)\n",
    "\n",
    "max_sperm = int(max(max(pred_spf), max(gt_spf)))\n",
    "\n",
    "plt.hist(pred_spf, bins=range(0, max_sperm, 1), alpha=0.5, color='red', label='Predicted')\n",
    "plt.hist(gt_spf, bins=range(0, max_sperm, 1), alpha=0.5, color='blue',label='Ground Truth')\n",
    "plt.show()\n",
    "\n",
    "max_frames = int(max(max(pred_fps), max(gt_fps)))\n",
    "\n",
    "plt.hist(pred_fps, bins=range(0, max_frames, 10), alpha=0.5, color='red', label='Predicted')\n",
    "plt.hist(gt_fps, bins=range(0, max_frames, 10), alpha=0.5, color='blue',label='Ground Truth')\n",
    "plt.show()\n",
    "\n",
    "print(\"Sperm Per Frame Pred - Mean: \", np.mean(pred_spf), \", Std: \", np.std(pred_spf), \", Normalized Mean: \", np.mean(pred_spf)/max_sperm, \", Normalized Std: \", np.std(pred_spf)/max_sperm)\n",
    "print(\"Sperm Per Frame GT - Mean: \", np.mean(gt_spf), \", Std: \", np.std(gt_spf), \", Normalized Mean: \", np.mean(gt_spf)/max_sperm, \", Normalized Std: \", np.std(gt_spf)/max_sperm)\n",
    "print(\"Frames Per Sperm Pred - Mean: \", np.mean(pred_fps), \", Std: \", np.std(pred_fps), \", Normalized Mean: \", np.mean(pred_fps)/max_frames, \", Normalized Std: \", np.std(pred_fps)/max_frames)\n",
    "print(\"Frames Per Sperm GT - Mean: \", np.mean(gt_fps), \", Std: \", np.std(gt_fps), \", Normalized Mean: \", np.mean(gt_fps)/max_frames, \", Normalized Std: \", np.std(gt_fps)/max_frames)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c370d7c",
   "metadata": {},
   "source": [
    "### Labeled Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "177f161d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create track data needed for calculation (Label, Birth Frame, Death Frame, 0 (no parent))\n",
    "\n",
    "def makeTrackData(df):\n",
    "    tracks = []\n",
    "\n",
    "    for s in range(0, df['sperm'].max() + 1):\n",
    "        cur_frames = df[df['sperm'] == s]['frame'].values\n",
    "        if len(cur_frames) > 0:\n",
    "            cur_birth = np.amin(cur_frames)\n",
    "            cur_death = np.amax(cur_frames)\n",
    "            cur_parent = 0\n",
    "            cur_track = [s, cur_birth, cur_death, cur_parent]\n",
    "            tracks.append(cur_track)\n",
    "\n",
    "    return np.array(tracks)\n",
    "\n",
    "pred_tracks = makeTrackData(pred)\n",
    "gt_tracks = makeTrackData(gt)\n",
    "pred_filter_tracks = makeTrackData(pred_filter)\n",
    "gt_filter_tracks = makeTrackData(gt_filter)\n",
    "\n",
    "#ref_tracks = []\n",
    "\n",
    "#for s in range(0, gt['sperm'].max() + 1):\n",
    "#    cur_frames = gt[gt['sperm'] == s]['frame'].values\n",
    "#    if len(cur_frames) > 0:\n",
    "#        cur_birth = np.amin(cur_frames)\n",
    "#        cur_death = np.amax(cur_frames)\n",
    "#        cur_parent = 0\n",
    "#        cur_track = [s, cur_birth, cur_death, cur_parent]\n",
    "#        ref_tracks.append(cur_track)\n",
    "\n",
    "#ref_tracks = np.array(ref_tracks)\n",
    "\n",
    "#comp_tracks = []\n",
    "\n",
    "#for s in range(0, pred['sperm'].max() + 1):\n",
    "#    cur_frames = pred[pred['sperm'] == s]['frame'].values\n",
    "#    if len(cur_frames) > 0:\n",
    "#        cur_birth = np.amin(cur_frames)\n",
    "#        cur_death = np.amax(cur_frames)\n",
    "#        cur_parent = 0\n",
    "#        cur_track = [s, cur_birth, cur_death, cur_parent]\n",
    "#        comp_tracks.append(cur_track)\n",
    "\n",
    "#comp_tracks = np.array(comp_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8e733fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  scipy.optimize import linear_sum_assignment\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "\n",
    "def makeTrajectoryData(pred,gt):\n",
    "\n",
    "    # Use Hungarian Algorithm to find best track matches between pred and gt in each frame\n",
    "    labels_ref = []\n",
    "    labels_comp = []\n",
    "    mapped_ref = []\n",
    "    mapped_comp = []\n",
    "\n",
    "    # For each frame\n",
    "    for f in range(0, pred['frame'].max() + 1):\n",
    "\n",
    "        mapped_ref_frame = []\n",
    "        mapped_comp_frame = []\n",
    "\n",
    "        # Get the labels in the frame\n",
    "        ref_data = gt[gt['frame'] == f][['sperm','x','y']].values\n",
    "        comp_data = pred[pred['frame'] == f][['sperm','x','y']].values\n",
    "\n",
    "        labels_ref_frame = ref_data[:,0].astype(int)\n",
    "        labels_comp_frame = comp_data[:,0].astype(int)\n",
    "\n",
    "        ref_centroids = ref_data[:,1:]\n",
    "        comp_centroids = comp_data[:,1:]\n",
    "\n",
    "        #labels_ref_frame = gt[gt['frame'] == f]['sperm'].values\n",
    "        #labels_comp_frame = pred[pred['frame'] == f]['sperm'].values\n",
    "        #print(labels_ref_frame.dtype, labels_ref_frame2.dtype)\n",
    "\n",
    "        # Get the centroids in the frame\n",
    "        #ref_centroids = gt[gt['frame'] == f][['x', 'y']].values\n",
    "        #comp_centroids = pred[pred['frame'] == f][['x', 'y']].values\n",
    "\n",
    "        # Compute the distance matrix\n",
    "        dist_matrix = cdist(ref_centroids, comp_centroids)\n",
    "\n",
    "        #print(dist_matrix.shape)\n",
    "\n",
    "        #import matplotlib.pyplot as plt\n",
    "        #plt.imshow(dist_matrix);plt.show()\n",
    "        #print(np.amin(dist_matrix))\n",
    "\n",
    "        # Use Hungarian Algorithm to find best matches\n",
    "        row_ind, col_ind = linear_sum_assignment(dist_matrix)\n",
    "\n",
    "        if (len(row_ind) != len(np.unique(row_ind))):\n",
    "            print(\"row issue!\")\n",
    "            print(row_ind.shape,np.unique(row_ind).shape)\n",
    "\n",
    "        if (len(col_ind) != len(np.unique(col_ind))):\n",
    "            print(\"col issue!\")\n",
    "            print(col_ind.shape,np.unique(col_ind).shape)\n",
    "\n",
    "        if len(labels_ref_frame) != len(np.unique(labels_ref_frame)):\n",
    "            print(\"labels_ref issue!\")\n",
    "        \n",
    "        if len(labels_comp_frame) != len(np.unique(labels_comp_frame)):\n",
    "            print(\"labels_comp issue!\")\n",
    "\n",
    "        #for r, c in zip(row_ind, col_ind):\n",
    "        #    print(r,c)\n",
    "\n",
    "        # Save the matches\n",
    "        for r, c in zip(row_ind, col_ind):\n",
    "            mapped_ref_frame.append(labels_ref_frame[r])\n",
    "            mapped_comp_frame.append(labels_comp_frame[c])\n",
    "\n",
    "            #labels_ref_frame.append(ref_labels[r])\n",
    "            #labels_comp_frame.append(comp_labels[c])\n",
    "            #mapped_ref_frame.append(gt[(gt['frame'] == f) & (gt['sperm'] == ref_labels[r])]['sperm'].values[0])\n",
    "            #mapped_comp_frame.append(pred[(pred['frame'] == f) & (pred['sperm'] == comp_labels[c])]['sperm'].values[0])\n",
    "\n",
    "        labels_ref.append(labels_ref_frame)\n",
    "        labels_comp.append(labels_comp_frame)\n",
    "        mapped_ref.append(mapped_ref_frame)\n",
    "        mapped_comp.append(mapped_comp_frame)\n",
    "\n",
    "    traj = {}\n",
    "    traj['labels_ref'] = labels_ref\n",
    "    traj['labels_comp'] = labels_comp\n",
    "    traj['mapped_ref'] = mapped_ref\n",
    "    traj['mapped_comp'] = mapped_comp\n",
    "\n",
    "    #print(labels_ref)\n",
    "    #print(labels_comp)\n",
    "    #print(mapped_ref)\n",
    "    #print(mapped_comp)\n",
    "\n",
    "    return traj\n",
    "\n",
    "traj = makeTrajectoryData(pred,gt)\n",
    "traj_filter = makeTrajectoryData(pred_filter,gt_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f200aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctc_metrics.utils.representations import merge_tracks, count_acyclic_graph_correction_operations\n",
    "\n",
    "def appendMergedTrajectory(ref_tracks, comp_tracks, traj):\n",
    "\n",
    "    new_tracks, new_labels, new_mapped = merge_tracks(\n",
    "        ref_tracks, traj[\"labels_ref\"], traj[\"mapped_ref\"])\n",
    "    traj[\"ref_tracks_merged\"] = new_tracks\n",
    "    traj[\"labels_ref_merged\"] = new_labels\n",
    "    traj[\"mapped_ref_merged\"] = new_mapped\n",
    "    new_tracks, new_labels, new_mapped = merge_tracks(\n",
    "        comp_tracks, traj[\"labels_comp\"], traj[\"mapped_comp\"])\n",
    "    traj[\"comp_tracks_merged\"] = new_tracks\n",
    "    traj[\"labels_comp_merged\"] = new_labels\n",
    "    traj[\"mapped_comp_merged\"] = new_mapped\n",
    "\n",
    "    return traj\n",
    "\n",
    "traj = appendMergedTrajectory(gt_tracks, pred_tracks, traj)\n",
    "traj_filter = appendMergedTrajectory(gt_filter_tracks, pred_filter_tracks, traj_filter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d95a992c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctc_metrics.utils.representations import count_acyclic_graph_correction_operations\n",
    "from ctc_metrics.metrics import (\n",
    "    valid, det, seg, tra, ct, tf, bc, cca, mota, hota, idf1, chota, mtml, faf,\n",
    "    op_ctb, op_csb, bio, op_clb, lnk\n",
    ")\n",
    "\n",
    "def computeMetrics(ref_tracks, comp_tracks, traj):\n",
    "\n",
    "    graph_operations = \\\n",
    "                count_acyclic_graph_correction_operations(\n",
    "                    ref_tracks, comp_tracks,\n",
    "                    traj[\"labels_ref\"], traj[\"labels_comp\"],\n",
    "                    traj[\"mapped_ref\"], traj[\"mapped_comp\"]\n",
    "                )\n",
    "\n",
    "    #print(graph_operations)\n",
    "\n",
    "    results = {}\n",
    "    results[\"DET\"] = det(**graph_operations)\n",
    "    _tra, _aogm, _aogm0 = tra(**graph_operations)\n",
    "    results[\"TRA\"] = _tra\n",
    "    results[\"AOGM\"] = _aogm\n",
    "    results[\"AOGM_0\"] = _aogm0\n",
    "    for key in (\"NS\", \"FN\", \"FP\", \"ED\", \"EA\", \"EC\"):\n",
    "        results[f\"AOGM_{key}\"] = graph_operations[key]\n",
    "\n",
    "    results[\"LNK\"] = lnk(**graph_operations)\n",
    "\n",
    "    results[\"CT\"] = ct(\n",
    "                comp_tracks, ref_tracks,\n",
    "                traj[\"labels_ref\"], traj[\"mapped_ref\"], traj[\"mapped_comp\"])\n",
    "\n",
    "    results[\"TF\"] = tf(\n",
    "        ref_tracks,\n",
    "        traj[\"labels_ref\"], traj[\"mapped_ref\"], traj[\"mapped_comp\"])\n",
    "\n",
    "\n",
    "    results.update(mota(\n",
    "        traj[\"labels_ref_merged\"], traj[\"labels_comp_merged\"],\n",
    "        traj[\"mapped_ref_merged\"], traj[\"mapped_comp_merged\"]))\n",
    "\n",
    "    results.update(hota(\n",
    "        traj[\"labels_ref_merged\"], traj[\"labels_comp_merged\"],\n",
    "        traj[\"mapped_ref_merged\"], traj[\"mapped_comp_merged\"]))\n",
    "\n",
    "    results.update(idf1(\n",
    "        traj[\"labels_ref_merged\"], traj[\"labels_comp_merged\"],\n",
    "        traj[\"mapped_ref_merged\"], traj[\"mapped_comp_merged\"]))\n",
    "    \n",
    "    return results\n",
    "\n",
    "results = computeMetrics(gt_tracks, pred_tracks, traj)\n",
    "results_filter = computeMetrics(gt_filter_tracks, pred_filter_tracks, traj_filter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eed869f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DET 0.9829948512585812\n",
      "TRA 0.8076571222314188\n",
      "AOGM 15453.5\n",
      "AOGM_0 80343.5\n",
      "AOGM_NS 0\n",
      "AOGM_FN 0\n",
      "AOGM_FP 1189\n",
      "AOGM_ED 5299\n",
      "AOGM_EA 5977\n",
      "AOGM_EC 0\n",
      "LNK 0.0\n",
      "CT 0.46808510638297873\n",
      "TF 0.9229395506934749\n",
      "MOTA 0.8260869565217391\n",
      "TP 6992\n",
      "FP 1189\n",
      "FN 0\n",
      "IDSW 27\n",
      "MULTI-ASSIGNMENTS 0\n",
      "Precision 0.854663244102188\n",
      "Recall 1.0\n",
      "HOTA 0.8793668644077607\n",
      "IDF1 0.866802873525341\n",
      "IDP 0.8038137147048038\n",
      "IDR 0.9405034324942791\n",
      "IDTP 6576.0\n",
      "IDFP 1605.0\n",
      "IDFN 416.0\n"
     ]
    }
   ],
   "source": [
    "for key,val in results.items():\n",
    "    print(key, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cdc7b95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DET 0.9798942731277533\n",
      "TRA 0.8067889922326077\n",
      "AOGM 12599.0\n",
      "AOGM_0 65208.5\n",
      "AOGM_NS 0\n",
      "AOGM_FN 0\n",
      "AOGM_FP 1141\n",
      "AOGM_ED 4189\n",
      "AOGM_EA 4846\n",
      "AOGM_EC 0\n",
      "LNK 0.0\n",
      "CT 0.5\n",
      "TF 0.9202412999566872\n",
      "MOTA 0.7948898678414097\n",
      "TP 5675\n",
      "FP 1141\n",
      "FN 0\n",
      "IDSW 23\n",
      "MULTI-ASSIGNMENTS 0\n",
      "Precision 0.832599765258216\n",
      "Recall 1.0\n",
      "HOTA 0.8619705068542\n",
      "IDF1 0.8463693859578897\n",
      "IDP 0.7755281690140845\n",
      "IDR 0.931453744493392\n",
      "IDTP 5286.0\n",
      "IDFP 1530.0\n",
      "IDFN 389.0\n"
     ]
    }
   ],
   "source": [
    "for key,val in results_filter.items():\n",
    "    print(key, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e0a2b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
